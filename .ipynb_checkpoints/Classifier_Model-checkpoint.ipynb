{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBoostClassifier, GradientBoostingClassifier\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./Image DataSet\\lionel_messi\\_111066400_messi.jpg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"C:/Users/jonua/opencv-4.x/data/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "eye_classifier = cv2.CascadeClassifier(\"C:/Users/jonua/opencv-4.x/data/haarcascades/haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_gray.shape\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_classifier.detectMultiScale(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = faces[0]\n",
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_01 = img_gray[y : y + h, x : x + w]\n",
    "plt.matshow(img_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,m,n = faces[1]\n",
    "img_02 = img_gray[b : b + m, a : a + n]\n",
    "a,b,m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 4)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color\n",
    "img_path = \"./Image DataSet\\lionel_messi\\_111066400_messi.jpg\"\n",
    "faces = crop_face(img_path)\n",
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = \"./Image DataSet/\"\n",
    "path_to_crpped = \"./Cropped Images/\"\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folders = []\n",
    "for entry in os.scandir(path_to_images):\n",
    "    if entry.is_dir():\n",
    "        img_folders.append(entry.path)\n",
    "img_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# if os.path.exists(path_to_crpped):\n",
    "#     shutil.rmtree(path_to_crpped)\n",
    "# os.mkdir(path_to_crpped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "crpped_img_folders = []\n",
    "celeb_folders = {}\n",
    "\n",
    "for folder_path in img_folders:\n",
    "    c = 1\n",
    "    name = folder_path.split('/')[-1]\n",
    "    #print(name)\n",
    "    celeb_folders[name] = []\n",
    "    celeb_dir = path_to_crpped + name\n",
    "    #print(celeb_dir)\n",
    "    if not os.path.exists(celeb_dir):\n",
    "        os.mkdir(celeb_dir)\n",
    "    crpped_img_folders.append(celeb_dir)\n",
    "    for entry in os.scandir(folder_path):\n",
    "        #print(entry)\n",
    "        roi_color = crop_face(entry.path)\n",
    "        if roi_color is not None:\n",
    "            crpp_img_name = name + str(c) + \".jpg\"\n",
    "            crpp_img_path = celeb_dir +  \"/\" + crpp_img_name\n",
    "            \n",
    "            #cv2.imwrite(crpp_img_path, roi_color)\n",
    "            celeb_folders[name].append(crpp_img_path)\n",
    "            c = c + 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelett_trans(img, mode='haar', level=5):\n",
    "    img_arr = img\n",
    "    img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_arr = np.float32(img_arr)\n",
    "    img_arr = img_arr/255\n",
    "    \n",
    "    coeffs = pywt.wavedec2(img_arr, mode, level=level)\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0] *= 0\n",
    "    \n",
    "    img_arr_H = pywt.waverec2(coeffs_H, mode)\n",
    "    img_arr_H *= 255\n",
    "    img_arr_H = np.uint8(img_arr_H)\n",
    "    \n",
    "    return img_arr_H\n",
    "\n",
    "img_har = wavelett_trans(faces, 'db1', 2)\n",
    "plt.matshow(img_har, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(celeb_folders, 'celeb_folders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_celeb = {}\n",
    "c = 0\n",
    "\n",
    "for name in celeb_folders:\n",
    "    encode_celeb[name] = c\n",
    "    c += 1\n",
    "encode_celeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for celeb, path in celeb_folders.items():\n",
    "    if not path:\n",
    "        continue\n",
    "    for train_data in path:\n",
    "        img_train = cv2.imread(train_data)\n",
    "        if img_train is None:\n",
    "            continue\n",
    "        scaled_raw_img = cv2.resize(img_train, (32,32))\n",
    "        img_har = wavelett_trans(img_train, level=5)\n",
    "        scaled_har_img = cv2.resize(img_har, (32,32))\n",
    "        stack_img = np.vstack((scaled_raw_img.reshape(32*32*3, 1), scaled_har_img.reshape(32*32, 1)))\n",
    "        X.append(stack_img)\n",
    "        Y.append(encode_celeb[celeb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(X, 'X')\n",
    "joblib.dump(Y, 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32*32*3 + 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X), 4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=40, test_size=0.3)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', SVC(C=10, kernel='rbf'))])\n",
    "pipe.fit(X_train, Y_train)\n",
    "pipe.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm' : {\n",
    "        'model' : SVC(gamma='auto', probability=True),\n",
    "        'params' : {\n",
    "            'svc__C' : [1,10,100,100],\n",
    "            'svc__kernel' : ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        }\n",
    "    },\n",
    "    'random_forest' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators' : [1,3,5,100]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'model' : LogisticRegression(),\n",
    "        'params' : {\n",
    "            'logisticregression__solver' : [ 'newton-cg', 'sag', 'saga'],\n",
    "            'logisticregression__C' : [1, 10, 20]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "best_esmti = {}\n",
    "\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scores.append({\n",
    "        'model' : algo,\n",
    "        'best_score' : clf.best_score_,\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    best_esmti[algo] = clf.best_estimator_\n",
    "df = pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\":[0.01,0.1,1.0,10,100],\n",
    "    \"n_estimators\":[5,50,250,500]\n",
    "}\n",
    "\n",
    "ada_cv = GridSearchCV(AdaBoostClassifier(), parameters, cv=5)\n",
    "ada_cv.fit(X_train,Y_train)\n",
    "\n",
    "ada = ada_cv.best_estimator_\n",
    "ada.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {  \n",
    "#     \"boosting_type\":[\"gbdt\",\"dart\",\"goss\",\"rf\"],\n",
    "#     \"learning_rate\":[0.01,0.1,1.0,10,100],\n",
    "#     \"max_depth\":[2,4,8,16,32],\n",
    "#     \"n_estimators\":[5,50,250,500]\n",
    "# }\n",
    "\n",
    "# lgbm_cv = GridSearchCV(LGBMClassifier(), parameters, cv=5)\n",
    "# lgbm_cv.fit(X_train,Y_train)\n",
    "\n",
    "# lgbm = lgbm_cv.best_estimator_\n",
    "# lgbm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"algorithm\":[\"ball_tree\",\"kd_tree\",\"brute\"],\n",
    "    \"metric\":[\"minkowski\",\"euclidean\",\"manhattan\"],\n",
    "    \"n_neighbors\":range(2,21),\n",
    "    \"weights\":[\"uniform\",\"distance\"]\n",
    "}\n",
    "\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), parameters, cv=5)\n",
    "knn_cv.fit(X_train,Y_train)\n",
    "\n",
    "knn = knn_cv.best_estimator_\n",
    "knn.fit(X_train,Y_train)\n",
    "knn.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_params'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LR = Pipeline([('scaler', StandardScaler()) , ('LR_classifier', LogisticRegression(solver='newton-cg', C=1))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LR.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LR.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe_LR, 'Model_LR_Demo.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clfier = best_esmti['logistic_regression']\n",
    "best_clfier.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_clfier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = best_esmti['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(Y_test, y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_dict.json', \"w\") as f:\n",
    "    f.write(json.dumps(encode_celeb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4ed460cfcc7e2c9e821aba7a20622d20c3464e7c33cc2771b0e6335ddeb7e1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
